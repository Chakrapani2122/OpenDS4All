# Model Assessment

Regardless of the machine learning classifier type chosen, there are many trade-offs involved in how to ensure the model is **robust**.  In some cases we can add regularization or adjust hyperparameters.  We can adjust the number of training examples, or use boosting or bagging.  This module focuses on techniques for ensuring models are robust.

For those students unfamiliar with model assessment, additional introductory material on data classification evaluation metrice will help them better understand the content of the other lectures.

## Directory Contents

* Training Robust Models [slides](TRAINING-ROBUST-MODELS-hyperparameters-tuning-validation.pptx).
* Training Robust Models [Jupyter notebook](TRAINING-ROBUST-MODELS-hyperparameters-tuning-validation.ipynb).
* DATA-CLASSIFICATION-Confusion-Matrix-Roc-intro [slides](DATA-CLASSIFICATION-Confusion-Matrix-Roc-intro.pptx)

## Release History

* Initial release, Susan Davidson and Zachary Ives, University of Pennsylvania, February 2020.
* Supporting introductory material, Xumin Liu, Rochester Institute of Technology, August 2022.
